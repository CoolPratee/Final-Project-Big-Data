In this project, I construct a scalable PySpark ETL pipeline in Databricks to ingest, clean and transform global demographic and geopolitical data of the REST Countries API. The workflow offers automatic normalization of the to-be-processed complex nested JSON structures, retrieving the key attributes (population, region, area, languages, capital, ISO codes) and generating a single analytics-ready Delta Lake table. The ultimate data allows performing efficient exploratory data, reporting, and dashboarding of demographic data by country and region.
